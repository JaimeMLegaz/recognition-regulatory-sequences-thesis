{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de las LSTM con los datos de 3' UTR <a class=\"tocSkip\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos primero las librerías necesarias para la realización del entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Activation, Conv1D, Flatten, Lambda, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante!!!**\n",
    "\n",
    "Cambiar el parámetro *allow_growth* es necesario para poder usar la GPU a su total capacidad. También es importante que los imports de arriba del todo sean tensorflow.keras y no keras solo (si no no va)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True # dynamically grow the memory used on the GPU\n",
    "session = InteractiveSession(config=config) # to log device placement (on which device the operation ran)\n",
    "                                            # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "set_session(session) # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento usando las cadenas reversed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición del conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafajorda/.conda/envs/tfm_env/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "readRDS = robjects.r['readRDS']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los objetos de train y test obtenidos del .Rmd de Jaime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = readRDS('../trainx.rds')\n",
    "testx = readRDS('../testx.rds')\n",
    "trainy = readRDS('../trainy.rds')\n",
    "testy = readRDS('../testy.rds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24289, 808, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trainx[2]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función que va a construir el modelo LSTM. Este modelo puede tener una o dos capas LSTM, en función de los parámetros de entrada que se le introducen. Si tiene una capa LSTM, tendrá además una capa de dropout, y si tiene dos capas LSTM, tendrá dos capas de dropout. La última capa del modelo es `softmax` con 2 nodos, luego nuestra salida deberá estar codificada en one-hot. El otro parámetro del modelo es el learning rate. Además, se usa como medida de loss la cross-entropía binaria, y como métrica el accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm(nodes1, dropout, lr, two_layers = False, nodes2 = 32):\n",
    "    model = Sequential()\n",
    "    if two_layers:\n",
    "        model.add(Bidirectional(LSTM(nodes1, return_sequences = True, input_shape = (202,4))))\n",
    "    else:\n",
    "        model.add(Bidirectional(LSTM(nodes1, input_shape = (202,4))))\n",
    "    model.add(Dropout(dropout))\n",
    "    if two_layers:\n",
    "        model.add(Bidirectional(LSTM(nodes2)))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "    opt = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer = opt, loss = \"binary_crossentropy\", \n",
    "                  metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos las variables de entrada y salida de la primera partición de las que hizo Jaime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trrx = np.array(trainx[0])\n",
    "tex = np.array(testx[0])\n",
    "trry = np.array(trainy[0])\n",
    "tey = np.array(testy[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos las secuencias para que los vectores one-hot sean de longitud 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trrx = np.array([np.array(seq).reshape(202,4) for seq in trrx])\n",
    "tex = np.array([np.array(seq).reshape(202,4) for seq in tex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reordenamos aleatoriamente los conjuntos de entrenamiento y test (no tiene por qué hacerse):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = pd.Series(np.squeeze(trry)).sample(len(np.squeeze(trry)), random_state = 1)\n",
    "tx = trrx[ty.index]\n",
    "ty = ty.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vy = pd.Series(np.squeeze(tey)).sample(len(np.squeeze(tey)), random_state = 1)\n",
    "vx = tex[vy.index]\n",
    "vy = vy.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el entrenamiento con 1 capa, 128 nodos y un learning rate de 0.001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24289 samples, validate on 6073 samples\n",
      "Epoch 1/25\n",
      "24289/24289 [==============================] - 8s 316us/sample - loss: 0.4199 - accuracy: 0.8052 - val_loss: 0.2632 - val_accuracy: 0.8918\n",
      "Epoch 2/25\n",
      "24289/24289 [==============================] - 5s 217us/sample - loss: 0.2369 - accuracy: 0.9085 - val_loss: 0.1805 - val_accuracy: 0.9335\n",
      "Epoch 3/25\n",
      "24289/24289 [==============================] - 5s 219us/sample - loss: 0.1870 - accuracy: 0.9294 - val_loss: 0.1617 - val_accuracy: 0.9391\n",
      "Epoch 4/25\n",
      "24289/24289 [==============================] - 5s 217us/sample - loss: 0.1762 - accuracy: 0.9334 - val_loss: 0.1485 - val_accuracy: 0.9447\n",
      "Epoch 5/25\n",
      "24289/24289 [==============================] - 5s 217us/sample - loss: 0.1632 - accuracy: 0.9411 - val_loss: 0.1485 - val_accuracy: 0.9458\n",
      "Epoch 6/25\n",
      "24289/24289 [==============================] - 5s 215us/sample - loss: 0.1662 - accuracy: 0.9375 - val_loss: 0.1424 - val_accuracy: 0.9485\n",
      "Epoch 7/25\n",
      "24289/24289 [==============================] - 5s 212us/sample - loss: 0.1497 - accuracy: 0.9448 - val_loss: 0.1348 - val_accuracy: 0.9519\n",
      "Epoch 8/25\n",
      "24289/24289 [==============================] - 5s 212us/sample - loss: 0.1425 - accuracy: 0.9481 - val_loss: 0.1476 - val_accuracy: 0.9437\n",
      "Epoch 9/25\n",
      "24289/24289 [==============================] - 5s 216us/sample - loss: 0.1421 - accuracy: 0.9489 - val_loss: 0.1204 - val_accuracy: 0.9575\n",
      "Epoch 10/25\n",
      "24289/24289 [==============================] - 5s 213us/sample - loss: 0.1336 - accuracy: 0.9522 - val_loss: 0.1171 - val_accuracy: 0.9555\n",
      "Epoch 11/25\n",
      "24289/24289 [==============================] - 5s 215us/sample - loss: 0.1339 - accuracy: 0.9522 - val_loss: 0.1784 - val_accuracy: 0.9234\n",
      "Epoch 12/25\n",
      "24289/24289 [==============================] - 5s 218us/sample - loss: 0.1355 - accuracy: 0.9512 - val_loss: 0.1164 - val_accuracy: 0.9567\n",
      "Epoch 13/25\n",
      "24289/24289 [==============================] - 5s 217us/sample - loss: 0.1236 - accuracy: 0.9561 - val_loss: 0.1101 - val_accuracy: 0.9590\n",
      "Epoch 14/25\n",
      "24289/24289 [==============================] - 5s 215us/sample - loss: 0.1188 - accuracy: 0.9567 - val_loss: 0.1165 - val_accuracy: 0.9560\n",
      "Epoch 15/25\n",
      "24289/24289 [==============================] - 5s 214us/sample - loss: 0.1195 - accuracy: 0.9577 - val_loss: 0.1820 - val_accuracy: 0.9282\n",
      "Epoch 16/25\n",
      "24289/24289 [==============================] - 5s 217us/sample - loss: 0.1116 - accuracy: 0.9610 - val_loss: 0.0943 - val_accuracy: 0.9659\n",
      "Epoch 17/25\n",
      "24289/24289 [==============================] - 5s 215us/sample - loss: 0.1073 - accuracy: 0.9630 - val_loss: 0.1039 - val_accuracy: 0.9625\n",
      "Epoch 18/25\n",
      "24289/24289 [==============================] - 5s 218us/sample - loss: 0.1087 - accuracy: 0.9614 - val_loss: 0.0972 - val_accuracy: 0.9648\n",
      "Epoch 19/25\n",
      "24289/24289 [==============================] - 5s 219us/sample - loss: 0.1041 - accuracy: 0.9629 - val_loss: 0.0958 - val_accuracy: 0.9649\n",
      "Epoch 20/25\n",
      "24289/24289 [==============================] - 5s 212us/sample - loss: 0.0990 - accuracy: 0.9650 - val_loss: 0.0974 - val_accuracy: 0.9644\n",
      "Epoch 21/25\n",
      "24289/24289 [==============================] - 5s 216us/sample - loss: 0.0982 - accuracy: 0.9662 - val_loss: 0.0978 - val_accuracy: 0.9644\n",
      "Epoch 22/25\n",
      "24289/24289 [==============================] - 5s 221us/sample - loss: 0.0963 - accuracy: 0.9668 - val_loss: 0.0979 - val_accuracy: 0.9630\n",
      "Epoch 23/25\n",
      "24289/24289 [==============================] - 5s 213us/sample - loss: 0.0930 - accuracy: 0.9677 - val_loss: 0.0865 - val_accuracy: 0.9704\n",
      "Epoch 24/25\n",
      "24289/24289 [==============================] - 5s 215us/sample - loss: 0.0907 - accuracy: 0.9685 - val_loss: 0.0881 - val_accuracy: 0.9689\n",
      "Epoch 25/25\n",
      "24289/24289 [==============================] - 5s 216us/sample - loss: 0.0919 - accuracy: 0.9679 - val_loss: 0.1003 - val_accuracy: 0.9641\n"
     ]
    }
   ],
   "source": [
    "batch_size = 125\n",
    "epochs = 25\n",
    "dropout = 0\n",
    "nodos1 = 128\n",
    "lr = 0.001\n",
    "# Cargamos el modelo y lo compilamos\n",
    "model = create_lstm(nodos1, dropout, lr)\n",
    "# Ejecutamos el modelo\n",
    "# Con la función to_categorical convertimos el vector de salida a one-hot\n",
    "historyIt = model.fit(tx,to_categorical(ty), batch_size= batch_size, epochs=epochs,\n",
    "                    validation_data = (vx, to_categorical(vy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection multiple                  136192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  514       \n",
      "=================================================================\n",
      "Total params: 136,706\n",
      "Trainable params: 136,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_env",
   "language": "python",
   "name": "tfm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
