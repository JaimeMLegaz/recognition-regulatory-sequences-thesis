---
title: "Training the network of the UTR experiment"
author: "Jaime MartÃ­nez Legaz"
output:
  html_document:
    df_print: paged
---

## Initial notes

This evaluation only modifies the third part of the experiment, the training. But, since it needs some data from the first part, and R has some problems writing and reading .csv files containing very big numbers (such us our treated sequences), we will have to do the three steps in the same file for it to work properly.

## Loading the libraries

Loading all required libraries

```{r, eval=FALSE, echo=FALSE}
library(tensorflow)

with(tf$device("/gpu:0"), {

})

```

```{r}
library(biomaRt)
library(SetupSequences)
library(keras)
library(caret)
```

## Obtaining the sequences

```{r}
library(tidyverse)
library(BSgenome)
library(BSgenome.Hsapiens.UCSC.hg38.masked)
library(GenomicRanges)


ml_table = readRDS(file = "ml_data_rf.rds") %>% 
  dplyr::select(class) %>% 
  rownames_to_column("id") %>% 
  tidyr::separate(id, c("gene", "seqnames", "start", "end", "strand", "tmp"), sep=":", remove=FALSE)
  

# converting to Granges object
ml_table_gr = makeGRangesFromDataFrame(ml_table, keep.extra.columns = TRUE)

# adding "chr" in front of seqnames
newStyle <- mapSeqlevels(seqlevels(ml_table_gr), "UCSC")
ml_table_gr <- renameSeqlevels(ml_table_gr, newStyle)

# Extract sequences using the package BSgenome
data = data.frame(
  id = ml_table$id,
  class = ml_table$class,
  sequence = BSgenome::getSeq(Hsapiens, ml_table_gr, as.character = TRUE)
)

table(data$class)
```

Next step is grouping all the non 3'UTR sequences into a group, so that we can compare 3'UTR sequences with non 3'UTR sequences regardless of the type.

```{r}
old_data <- data # Needed for the valdation tests

data$detailclass = data$class
data$class = ifelse(data$class %in% "UTR", "UTR", "Non_3_UTR")  %>% as.factor() %>% as.integer()
data$class <- data$class - 1 #0 = No3UTR 1 = 3UTR
table(data$class)
```

```{r}
# Validation test
test1 = table(data$class)["0"] == nrow(data) - table(old_data$class)["UTR"]; if (test1) print ("Correct 1") else print ("ERROR 1")
test2 = table(data$class)["1"] == table(old_data$class)["UTR"]; if (test2) print ("Correct 2") else print ("ERROR 2")

```

We will separate these sequences into the "Positive" group (3'UTR) and the "Negative" group (non-3'UTR).

```{r}
PositiveSequences = data[data$class == 1,]
NegativeSequences = data[data$class == 0,]
```

And save these sequences to a file.

```{r}
write.csv(PositiveSequences,file="PositiveUTRSequences_untreated_sid", row.names = FALSE, quote = FALSE)
write.csv(NegativeSequences,file="NegativeUTRSequences_untreated_sid", row.names = FALSE, quote = FALSE)
```

Next we have to obtain the sequences to evaluate. These are contained in two rds files:

```{r}

seqs1 <- read_rds("table_GCB1_sequence.rds")
seqs2 <- read_rds("table_GCB2_sequence.rds")
evalSequences <- rbind(seqs1, seqs2)

evalSequences$id <- as.character(evalSequences$id)
evalSequences$dna_sequence <- as.character(evalSequences$dna_sequence)

colnames(evalSequences) <- c("id", "sequence")

```

## Treating the sequences

First, we recover the sequences we obtained with ensembl.

```{r}
PosSequences <- read.csv("PositiveUTRSequences_untreated_sid")
NegSequences <- read.csv("NegativeUTRSequences_untreated_sid")
```

Next we start with the treatment of sequences. We have to:

- Reverse them
- Make sure all sequences are 250 characters long
- One-hot encode them

For that, we need some functions from the custom package developed for this project.

```{r}
# We save the sequences for later use
PosSequences$rawseq <- PosSequences$sequence
NegSequences$rawseq <- NegSequences$sequence
evalSequences$rawseq <- evalSequences$sequence

# Example of sequence: AACCGT
PosSequences$sequence[1]  # Example of a positive sequence
NegSequences$sequence[1]  # Example of a negative sequence
evalSequences$sequence[1]  # Example of an evaluation sequence
```


```{r}
old_seq = PosSequences$sequence[1]

# strReverse:  AACCGT --> TGCCAA
PosSequences$sequence <- strReverse(PosSequences$sequence)
NegSequences$sequence <- strReverse(NegSequences$sequence)
evalSequences$sequence <- strReverse(evalSequences$sequence)

PosSequences$sequence[1]  # The positive sequence, once reversed
NegSequences$sequence[1]  # The negative sequence, once reversed
evalSequences$sequence[1]  # The evaluation sequence, once reversed

# Validation
doublereverse = strReverse(PosSequences$sequence[1])
test1 = doublereverse == old_seq; if (test1) print ("Correct 1") else print ("ERROR 1")
```


```{r}
# padding_sequences: Inserts padding characters ("X") in sequences shorter than 250 characters, and trims sequences longer than 250 characters
PosSequences$sequence <- padding_sequences(PosSequences$sequence)
NegSequences$sequence <- padding_sequences(NegSequences$sequence)
evalSequences$sequence <- padding_sequences(evalSequences$sequence)

PosSequences$sequence[1]  # The positive sequence, with some characters added so it can be 250 characters long
NegSequences$sequence[1]  # The negative sequence, trimmed so it becomes 250 characters long
evalSequences$sequence[1]  # The evaluation sequence, with some characters added so it becomes 250 characters long

# Validation
test1 = all(sapply(list(min(nchar(PosSequences$sequence)),max(nchar(PosSequences$sequence)), mean(nchar(PosSequences$sequence))), function(x) x == 250))
test2 = all(sapply(list(min(nchar(NegSequences$sequence)),max(nchar(NegSequences$sequence)), mean(nchar(NegSequences$sequence))), function(x) x == 250))
test3 = all(sapply(list(min(nchar(evalSequences$sequence)),max(nchar(evalSequences$sequence)), mean(nchar(evalSequences$sequence))), function(x) x == 250))
if (test1) print ("Correct 1") else print ("ERROR 1")
if (test2) print ("Correct 2") else print ("ERROR 2")
if (test3) print ("Correct 3") else print ("ERROR 3")
```

```{r}
# to_onehot:   TGCCAA --> 00010010010010001000    (A = 1000, C = 0100, G = 0010, T = 0001)
PosSequences$sequence <- to_onehot(PosSequences$sequence)
NegSequences$sequence <- to_onehot(NegSequences$sequence)
evalSequences$sequence <- to_onehot(evalSequences$sequence)

PosSequences$sequence[1]  # The positive sequence, reversed, padded and one-hot encoded
NegSequences$sequence[1]  # The negative sequence, reversed, trimmed and one-hot encoded
evalSequences$sequence[1]  # The evaluation sequence, reversed, padded and one-hot encoded


# Validation
test1 = all(sapply(list(min(nchar(PosSequences$sequence)),max(nchar(PosSequences$sequence)), mean(nchar(PosSequences$sequence))), function(x) x == 1250))
test2 = all(sapply(list(min(nchar(NegSequences$sequence)),max(nchar(NegSequences$sequence)), mean(nchar(NegSequences$sequence))), function(x) x == 1250))
test3 = all(sapply(list(min(nchar(evalSequences$sequence)),max(nchar(evalSequences$sequence)), mean(nchar(evalSequences$sequence))), function(x) x == 1250))
if (test1) print ("Correct 1") else print ("ERROR 1")
if (test2) print ("Correct 2") else print ("ERROR 2")
if (test3) print ("Correct 3") else print ("ERROR 3")
```

```{r}
# Final check: Since some of the sequences might be corrupt, we will delete the ones that are corrupt, if they exist
# We can know if a sequence is corrupt by looking for the W character. When one-hot encoding, we encoded everything that was not an A, T, C or G with a "W"

if (any(grepl("W",PosSequences$sequence))){
  print("Found 'W'")
  PosSequences <- PosSequences[-which(grepl("W",PosSequences$sequence)),]
}
  
if (any(grepl("W",NegSequences$sequence))){
  print("Found 'W'")
  NegSequences <- NegSequences[-which(grepl("W",NegSequences$sequence)),]
}

if (any(grepl("W",evalSequences$sequence))){
  print("Found 'W'")
  evalSequences <- evalSequences[-which(grepl("W",evalSequences$sequence)),]
}

```

Once treated, we can save them in a file for later use.

```{r}
fileCon<-file("Pos3UTR")
write.table(PosSequences$sequence,file = fileCon, quote=FALSE, row.names = FALSE, col.names = FALSE)
fileCon<-file("Neg3UTR")
write.table(NegSequences$sequence,file = fileCon, quote=FALSE, row.names = FALSE, col.names = FALSE)
```

## Training the network
First we have to recover the treated data.

```{r}
PosUTR <- scan(file="PosUTR",what="character")
length(PosUTR)
PosSequences_nodup <- PosSequences[-which(duplicated(PosUTR)),]
PosUTR <- PosUTR[-which(duplicated(PosUTR))]
length(PosUTR)

NegUTR <- scan(file="NegUTR",what="character")
length(NegUTR)
NegSequences_nodup <- NegSequences[-which(duplicated(NegUTR)),]
NegUTR <- NegUTR[-which(duplicated(NegUTR))]
length(NegUTR)

# Validation test
test1 = all(NegSequences_nodup$sequence == NegUTR) 
test2 = all(PosSequences_nodup$sequence == PosUTR)
if (test1) print ("Correct 1") else print ("ERROR 1")
if (test2) print ("Correct 2") else print ("ERROR 2")
```

Now we face an issue with our sequences. They are 1250 characters long strings, but R sees them as indivisible elements. We have to transform them before working with them, turning each 1250 characters long sequence into 1250 sequences of only one character.

```{r}
posNum <- length(PosUTR) # Number of positive sequences
SeqUTR <- append(PosUTR,NegUTR)

old_seq = SeqUTR[1] # For validation tests

n2 <- nchar(SeqUTR[1]) -1 # Number of divisions to make

secuenciasOH <- sapply(1 + 1*0:n2, function(z) substr(SeqUTR, z, z))  # Obtaining the split characters
df <- data.frame(secuenciasOH, "Value" = 0) # Saving them into a dataframe
indx <- sapply(df, is.factor) 
df[indx] <- lapply(df[indx], function(x) as.character(x)) # Factor --> char conversion

df[1:posNum,]$Value <- 1 # We have the value of the positive sequences to positive

table(df$Value)

# Validation tests
test1 = paste(unlist(secuenciasOH[1,]),sep="", collapse="") == old_seq; if (test1) print ("Correct 1") else print ("ERROR 1")
test2 = table(df$Value)["0"] == length(NegUTR); if (test2) print ("Correct 2") else print ("ERROR 2")
test3 = table(df$Value)["1"] == length(PosUTR); if (test3) print ("Correct 3") else print ("ERROR 3")
test4 = all(length(PosUTR) + length(NegUTR) == length(SeqUTR), length(SeqUTR) == nrow(df)); if (test4) print ("Correct 4") else print ("ERROR 4")
```

Since we are going to train five different models, we will divide our data into five different dataframes. Each of them will have the same number of positive and negative sequences. Since we don't have many positive sequences, we will train every model with every positive sequences. This way, every model will be trained with the same set of positive sequences, but a different set of negative sequences.

```{r}
# Select all the negative sequences
set.seed(1234)
chosenSeqs <- sample(nrow(df) - posNum, size = posNum*5, replace = FALSE, prob = NULL) # Selected rows from 0 to max-posNum
chosenSeqs <- chosenSeqs + posNum

sets <- list()

sets[[1]] <- 1:posNum
sets[[2]] <- (posNum+1):(posNum*2)
sets[[3]] <- ((posNum*2)+1):(posNum*3)
sets[[4]] <- ((posNum*3)+1):(posNum*4)
sets[[5]] <- ((posNum*4)+1):(posNum*5)

```

```{r}

df.a <- df[c(1:posNum,chosenSeqs[sets[[1]]]),]
df.b <- df[c(1:posNum,chosenSeqs[sets[[2]]]),]
df.c <- df[c(1:posNum,chosenSeqs[sets[[3]]]),]
df.d <- df[c(1:posNum,chosenSeqs[sets[[4]]]),]
df.e <- df[c(1:posNum,chosenSeqs[sets[[5]]]),]

dfs <- list(df.a, df.b, df.c, df.d, df.e) # 

totalSeq = (nrow(df.a) + nrow(df.b) + nrow(df.c) + nrow(df.d) + nrow(df.e)) 
length(SeqUTR) - totalSeq # Number of sequences that do not appear in the dataframes
test1 = all(sapply(list(table(df.a$Value),table(df.b$Value), table(df.c$Value), table(df.d$Value)), function(x) x == table(df.e$Value)))
test2 = table(df.a$Value)["0"] == posNum
test3 = table(df.a$Value)["1"] == posNum
if (test1) print ("Correct 1") else print ("ERROR 1")
if (test2) print ("Correct 2") else print ("ERROR 2")
if (test3) print ("Correct 3") else print ("ERROR 3")

```

```{r echo=FALSE, eval=FALSE}

start = posNum + 1
end = start + posNum - 1
df.a <- df[c(1:posNum,start:end),]
df.b <- df[c(1:posNum,(start + posNum):(end + posNum)),]
df.c <- df[c(1:posNum,(start + (posNum*2)):(end + (posNum*2))),]
df.d <- df[c(1:posNum,(start + (posNum*3)):(end + (posNum*3))),]
df.e <- df[c(1:posNum,(start + (posNum*4)):(end + (posNum*4))),]

dfs <- list(df.a, df.b, df.c, df.d, df.e) # 

# Validation tests
totalSeq = (nrow(df.a) + nrow(df.b) + nrow(df.c) + nrow(df.d) + nrow(df.e)) 
length(SeqUTR) - totalSeq # Number of sequences that do not appear in the dataframes
test1 = all(sapply(list(table(df.a$Value),table(df.b$Value), table(df.c$Value), table(df.d$Value)), function(x) x == table(df.e$Value)))
test2 = table(df.a$Value)["0"] == posNum
test3 = table(df.a$Value)["1"] == length(SeqUTR) - table(df.a$Value)["0"]
if (test1) print ("Correct 1") else print ("ERROR 1")
if (test1) print ("Correct 2") else print ("ERROR 2")
if (test1) print ("Correct 3") else print ("ERROR 3")
```

Now we have to divide our data into Training and Test for our model training.

```{r}

output <- c("Value")
trains <- list()
tests <- list()
usedForTrainPos <- list()
usedForTrainNeg <- list()

set.seed(1234)

for (i in 1:5){
  partition <- createDataPartition(dfs[[i]][[output]],
                                     p = 0.8,
                                     list = FALSE,
                                     times = 1)
  trains <- append(trains, list(dfs[[i]][partition,])) # 28210
  tests <- append(tests, list(dfs[[i]][-partition,])) # 7852
  # Sum of both: 35262

  partPos <- partition[partition <= posNum]
  partNeg <- partition[partition > posNum]
  partNeg <- partNeg - posNum
  
  usedForTrainPos <- append(usedForTrainPos,list(unlist(partPos)))
  usedForTrainNeg <- append(usedForTrainNeg,list(unlist(chosenSeqs[sets[[i]][partNeg]])))
}

# Validation test

total = 0

for (i in 1:5) {
  total = total + nrow(trains[[i]]) + nrow(tests[[i]])
}

test1 = total == totalSeq; if (test1) print ("Correct 1") else print ("ERROR 1")
test2 = sum(duplicated(usedForTrainPos)) == 0; if (test2) print ("Correct 2") else print ("ERROR 2")
test3 = sum(duplicated(usedForTrainNeg)) == 0; if (test3) print ("Correct 3") else print ("ERROR 3")

#usedForTrainPos <- usedForTrainPos[-which(duplicated(usedForTrainPos))] # Only the positive genes could be duplicated

```

```{r}
# Checking the type distribution of the train sets

for (i in 1:5){
  negtr <- usedForTrainNeg[[i]]
  print(min(negtr))
  print(max(negtr))
  print(table(NegSequences_nodup$detailclass[negtr]))
}


```

Once divided, we have to adapt the data to the format the model expects.

```{r}
train.x <- list()
train.y <- list()

test.x <- list()
test.y <- list()

for (i in 1:5){
  train.x <- append(train.x, list(data.matrix(trains[[i]][,1:1250])))
  train.y <- append(train.y, list(data.matrix(trains[[i]][,1251])))
  
  test.x <- append(test.x, list(data.matrix(tests[[i]][,1:1250])))
  test.y <- append(test.y, list(data.matrix(tests[[i]][,1251])))

  train.x[[i]] <- array_reshape(train.x[[i]], c(nrow(trains[[i]]),1250,1))
  test.x[[i]] <- array_reshape(test.x[[i]], c(nrow(tests[[i]]),1250,1))
 }
```

We have to prepare the dataframe that will contain the sequences and the output of the models.

```{r, eval=FALSE, echo=FALSE}
# Next step is making a dataframe of every control gene and predicting positive or negative
genesN <- NegSequences_nodup
genesP <- PosSequences_nodup

 ##### We have to make some transformations to these secuences

n2 <- nchar(genesN$sequence[1]) - 1

secuencesOH <- sapply(1 + 1*0:n2, function(z) substr(genesN$sequence, z, z))  
dfn <- data.frame(secuencesOH, class=genesN$detailclass, id=genesN$id) 
indx <- sapply(dfn, is.factor) 
dfn[indx] <- lapply(dfn[indx], function(x) as.character(x))  #

secuencesOH <- sapply(1 + 1*0:n2, function(z) substr(genesP$sequence, z, z))  
dfp <- data.frame(secuencesOH, class=genesP$detailclass, id=genesP$id) 
indx <- sapply(dfp, is.factor) 
dfp[indx] <- lapply(dfp[indx], function(x) as.character(x))  

# We have got a dataframe with the ensembl_id, sequence and hgnc symbol in genesP and genesN, and a dataframe with the split sequence and hgnc symbol in dfp and dfn

finalSequencesN <- data.matrix(dfn[,1:1250])
finalSequencesN <- array_reshape(finalSequencesN,c(nrow(finalSequencesN),1250,1))
finalSequencesP <- data.matrix(dfp[,1:1250])
finalSequencesP <- array_reshape(finalSequencesP,c(nrow(finalSequencesP),1250,1))

genesP$model1 <- 0
genesP$model2 <- 0
genesP$model3 <- 0
genesP$model4 <- 0
genesP$model5 <- 0

genesN$model1 <- 0
genesN$model2 <- 0
genesN$model3 <- 0
genesN$model4 <- 0
genesN$model5 <- 0

```

```{r}
# Next step is making a dataframe of every control gene and predicting positive or negative
genes <- evalSequences

 ##### We have to make some transformations to these secuences

n2 <- nchar(genes$sequence[1]) - 1

secuencesOH <- sapply(1 + 1*0:n2, function(z) substr(genes$sequence, z, z))  
df <- data.frame(secuencesOH, id=genes$id) 
indx <- sapply(df, is.factor) 
df[indx] <- lapply(df[indx], function(x) as.character(x))  #


# We have got a dataframe with the ensembl_id, sequence and hgnc symbol in genesP and genesN, and a dataframe with the split sequence and hgnc symbol in dfp and dfn

finalSequences <- data.matrix(df[,1:1250])
finalSequences <- array_reshape(finalSequences,c(nrow(finalSequences),1250,1))

genes$model1 <- 0
genes$model2 <- 0
genes$model3 <- 0
genes$model4 <- 0
genes$model5 <- 0


```

Now it is time to build our model. It follows the specifications mentioned in the thesis report. 

```{r}
  batch_size <- 125
  epochs <- 25 
  input_shape <- c(1250,1)
  learn_rate = 0.0001
  
  modelConvolu <- keras_model_sequential()
  modelConvolu %>% 
    layer_conv_1d(filters = 50, kernel_size = 75, activation = "relu", input_shape = input_shape)%>%
    layer_flatten() %>%
    layer_dense(units = 50, activation = 'relu') %>% 
    layer_dense(units = 1, activation="sigmoid") %>%
    
    summary(model)
  
  modelConvolu %>% compile(
    loss = loss_binary_crossentropy,
    optimizer = optimizer_nadam(lr = learn_rate),
    metrics = c('accuracy')
  )
```

And now we train that model with the data obtained. After each training epoch, we will obtain certain statistics related to the sensitivity and specificity of the model, since they are not metrics that Keras can return from the model.

```{r}
config = tensorflow::tf$ConfigProto(gpu_options = list(allow_growth = TRUE))
sess = tensorflow::tf$Session(config = config)
keras::k_set_session(session = sess)
```

```{r}
#with(tf$device("/device:GPU:0"), {


for (i in 1:5){
  
  sens <- NULL
  spec <- NULL
  history <- NULL
 
  
   modelConvolu <- keras_model_sequential()
  modelConvolu %>% 
    layer_conv_1d(filters = 48, kernel_size = 75, activation = "relu", input_shape = input_shape)%>%
    layer_flatten() %>%
    layer_dense(units = 50, activation = 'relu') %>% 
    layer_dense(units = 1, activation="sigmoid") 
  
  modelConvolu %>% compile(
    loss = loss_binary_crossentropy,
    optimizer = optimizer_nadam(lr = learn_rate),
    metrics = c('accuracy')
  )
  
    for (epoch in 1:epochs){
    historial <- modelConvolu %>% fit(
      x = train.x[[i]],
      y = train.y[[i]],
      epochs = 1,  
      batch_size = batch_size, 
      validation_data = list(test.x[[i]], test.y[[i]]),
      verbose = 2)
    
    history <- c(history, historial)
  }
  ## Prediction 
  pred <- modelConvolu %>% predict(finalSequences, batch_size = batch_size)
  #genes[,3+i] = round(pred)
  genes[,3+i] = pred
  
}

#})
```


Borrar esto de abajo, es solo para guardar cosas pa luego

```{r} 
#genesP <- saveGenesP
#genesN <- saveGenesN

saveGenes <- genes

```

Next we will save some statistics from the evaluation of the genes. First of all, we have to prepare two structures for each of the gene groups:
- finalEval: Dataframe containing all the data about these genes: From their names and sequences, to some statistics such as success or failure of the evaluation of each model.
- summary: Dataframe that contains general stats about the evaluation of all genes. All information appearing here will be taken from the finalEval dataframe. Each row corresponds to the stats of one specific model.

```{r}
models <- c("Model1","Model2","Model3","Model4","Model5")

# subtipos <- as.character(unique(data$detailclass))

summary <- data.frame(matrix(0, ncol=7, nrow=5))
colnames(summary) <-  c("TrainedRight","TrainedWrong","UntrainedRight","UntrainedWrong", "RateTrainedRight", "RateUntrainedRight", "3-UTR")

finalEval <- genes

str(summary)
str(finalEval)
```

Next we have to specify which genes were actually used to train the models. These genes have already been specified, but since now we are splitting them into two groups (Positives and Negatives) we have to correct the indexes of the second group (since old gene #3658 corresponds to the 1st Negative gene)

```{r, eval = FALSE}
trainNegIndexes <- usedForTrainNeg # Borrar despues, y la sig tambien
#usedForTrainNeg <- saveVariable
# First negative sequence would be trainNegIndexes = 1, usedForTrainNeg = 17631

for (i in 1:5) { # Correction of negative gene indexes
  trainNegIndexes[[i]] <- trainNegIndexes[[i]] - posNum
}

```

Now that we have corrected the indexes, we will create the summaries. For that, we have to check the success of failure of the evaluation of the genes, differentiating between genes used or not used for the training of the networks.

```{r, eval = FALSE}
allRowsN <- 1:nrow(genesN)
allRowsP <- 1:nrow(genesP)


for (i in 1:5){
  trainedWithNeg <-trainNegIndexes[[i]]
  notTrainedWithNeg <- allRowsN[-trainedWithNeg]
  
  countTrainNeg <- sum(finalEvalN[trainedWithNeg,(5+i)] == 0) # Counts the number of genes used for training correctly predicted as negative
  countUntrainNeg <- sum(finalEvalN[notTrainedWithNeg,(5+i)] == 0) # Counts the number of genes not used for training correctly predicted as negative
  summaryN[i,] <- c(countTrainNeg,length(trainedWithNeg) - countTrainNeg, countUntrainNeg, length(notTrainedWithNeg) - countUntrainNeg, countTrainNeg/length(trainedWithNeg), countUntrainNeg/length(notTrainedWithNeg), 0)
  
  trainedWithPos <-usedForTrainPos[[i]]
  notTrainedWithPos <- allRowsP[-trainedWithPos]
  
  countTrainPos <- sum(finalEvalP[trainedWithPos,(5+i)] == 1) # Counts the number of genes used for training correctly predicted as positive
  countUntrainPos <- sum(finalEvalP[notTrainedWithPos,(5+i)] == 1) # Counts the number of genes not used for training correctly predicted as positive
  summaryP[i,] <- c(countTrainPos,length(trainedWithPos) - countTrainPos, countUntrainPos, length(notTrainedWithPos) - countUntrainPos, countTrainPos/length(trainedWithPos), countUntrainPos/length(notTrainedWithPos), 1)
}
```

The finalEval dataframe requieres some extra columns that we will now add. This columns refer to the training and evaluation of the models: A "1" in a certain column indicates that the gene referenced by the row was used by that model either in its training or in its evaluation. A "0" means it was not used for that task in that specific model.

```{r, eval = FALSE}
# 11 to 15 
finalEvalP$trainingModel1 <- 0
finalEvalP$trainingModel2 <- 0
finalEvalP$trainingModel3 <- 0
finalEvalP$trainingModel4 <- 0
finalEvalP$trainingModel5 <- 0

#16 to 20
finalEvalP$evaluationModel1 <- 0
finalEvalP$evaluationModel2 <- 0
finalEvalP$evaluationModel3 <- 0
finalEvalP$evaluationModel4 <- 0
finalEvalP$evaluationModel5 <- 0

# 11 to 15
finalEvalN$trainingModel1 <- 0
finalEvalN$trainingModel2 <- 0
finalEvalN$trainingModel3 <- 0
finalEvalN$trainingModel4 <- 0
finalEvalN$trainingModel5 <- 0

#16 to 20
finalEvalN$evaluationModel1 <- 0
finalEvalN$evaluationModel2 <- 0
finalEvalN$evaluationModel3 <- 0
finalEvalN$evaluationModel4 <- 0
finalEvalN$evaluationModel5 <- 0

```

And now we have to fill those columns. 

```{r, eval = FALSE}
for(i in 1:5){

  trainedWith <- chosenSeqs[sets[[i]]]
  trainedWith <- trainedWith - posNum # Due to chosenSeqs containing only negative sequences
  
  finalEvalN[trainedWith,15+i] <- 1 # Default value we will set is 1 for the evaluation and 0 for the training, and later we will override them if incorrect
  
  for (j in usedForTrainPos[[i]]){ # If the gene was used in the training, the corresponding training column gets a "1"
      finalEvalP[j,10+i] <- 1
  }
  
  for (j in allRowsP[-usedForTrainPos[[i]]]){ # If not, the corresponding evaluation column gets a "1"
      finalEvalP[j,15+i] <- 1
  }
    
  finalEvalN[trainNegIndexes[[i]],10+i] <- 1 # We already have the list of negative genes used for the training of that model, so we set their training value to 1...
  finalEvalN[trainNegIndexes[[i]],15+i] <- 0 # ...and their evaluation value to 0
  
}

```

If everything was done correctly, no row should have a 1 in both training and evaluation of a certain model. The following block checks that:

```{r, eval = FALSE}
# If done correctly, this should output 10 zeroes
for (i in 1:5){
  print(sum(finalEvalP[,10+i] == 1 && finalEvalP[,15+i] == 1))
  print(sum(finalEvalN[,10+i] == 1 && finalEvalN[,15+i] == 1))
}

```

Now just a small fix for clarity (...)

```{r, eval = FALSE}
for (i in 1:5) {
  finalEvalN[,(5+i)] <- 1 - finalEvalN[,(5+i)]
}
```


```{r}

finalEval$detailedResult <- finalEval$model1 + finalEval$model2 + finalEval$model3 + finalEval$model4 + finalEval$model5
finalEval$simpleResult <- 0
finalEval$simpleResult[finalEval$detailedResult >=2.5] <- 1
write.csv(finalEval,file="finalEvaluationB", row.names = FALSE, col.names = FALSE, quote = FALSE)
```

```{r, eval = FALSE}

#genesP

finalEvalN$totalSum <- finalEvalN$model1 + finalEvalN$model2 + finalEvalN$model3 + finalEvalN$model4 + finalEvalN$model5
finalEvalN$UTR3 <- 0
#write.csv(genesN,file="Results/finalEvaluationN", row.names = FALSE, col.names = FALSE, quote = FALSE)
#genesN
allGenes <- rbind(finalEvalP,finalEvalN)
write.csv(allGenes,file="finalEvaluationAllGenes", row.names = FALSE, col.names = FALSE, quote = FALSE)

allFrame <- rbind(summaryP,summaryN)
write.csv(allFrame,file="stats",row.names = FALSE, col.names = FALSE, quote = FALSE)

```

First we generate a dataframe that contains information about every different subtype.

```{r}
types <- unique(allGenes$detailclass)
types <- types[-which(types == "UTR")] # We are not interested in 3'UTR sequences since those are not negative sequences, and, because of that, are already separated from the rest
typeStats <- data.frame(matrix(0, ncol=5, nrow=length(types)))
colnames(typeStats) <-  c("Type", "NumberSuccess","NumberFailures","RateSuccess","RateTraining")
typeStats$Type <- types
```

Then we calculate the values

```{r}

allTrainNeg <- NULL

for (i in 1:5){
  allTrainNeg <- c(allTrainNeg, unlist(trainNegIndexes[[i]]))
}

#allTrainNeg <- allTrainNeg + posNum

for (i in 1:length(types)){
#  trainedWith <- usedForTrainNeg[[i]]
  
  numberSuccess <- sum(finalEvalN[finalEvalN$detailclass == typeStats$Type[i],6:10] == 1) # Counts the number of genes used for training incorrectly predicted
  numberFailures <- sum(finalEvalN[finalEvalN$detailclass == typeStats$Type[i],6:10] == 0) # Counts the number of genes not used for training correctly predicted
  
  trainEvalN <- finalEvalN[allTrainNeg,]
  numberTrain <- nrow(trainEvalN[trainEvalN$detailclass == typeStats$Type[i],])
  
  typeStats[i,] <- c(typeStats$Type[i], numberSuccess,numberFailures, numberSuccess/(numberSuccess + numberFailures), numberTrain/length(allTrainNeg))
}

write.csv(typeStats,file="typeStats",row.names = FALSE, col.names = FALSE, quote = FALSE)

```
